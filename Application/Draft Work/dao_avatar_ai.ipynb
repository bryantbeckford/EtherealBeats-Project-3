{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoeNq_rJ2n1e"
      },
      "source": [
        "# ***DAO Membership Program***\n",
        "\n",
        "**DAO Member Avatar: Using Python 'Replicate' Library for Machine Learning, AI-Generated Dao Member Avatars, Associated with Unique MIDs. DAO Memberships to be distributed as NFTs (DAOs may be governed using NFTs or tokens that grant members voting rights. The rules of the DAO are stored on an open-sourced blockchain.**\n",
        "\n",
        "DAO == Decentralized autonomous organization\n",
        "\n",
        "MID == Member Identifier\n",
        "\n",
        "While beyond the scope of this initial DAO project, we could store the resulting DAO Member Avatars and other such data off blockchain through an IPFS, or inter-planetary file system, such as Pinata, where data would be stored through a cryptographic hash, returning a unique CID, or content identifier.  The CID would serve as both the address and verification of the data.\n",
        "\n",
        "\"IPFS is a peer-to-peer distributed file system that is used primarily for data that can't be stored on a blockchain.\" (c.f. https://docs.pinata.cloud/docs/what-is-ipfs)\n",
        "\n",
        "References:\n",
        "- https://ethereum.org/en/dao/\n",
        "- https://docs.pinata.cloud/docs/what-is-ipfs\n",
        "- https://www.binance.com/en/blog/nft/what-is-a-dao-and-how-does-it-benefit-nfts-421499824684903992"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzdeYL4dy5_G",
        "outputId": "6c1ecf88-dcf0-4ea9-d3e9-1df9883ed210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n",
            "Collecting replicate\n",
            "  Downloading replicate-0.21.0-py3-none-any.whl (34 kB)\n",
            "Collecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (23.2)\n",
            "Requirement already satisfied: pydantic>1 in /usr/local/lib/python3.10/dist-packages (from replicate) (1.10.13)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2023.7.22)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.1.3)\n",
            "Installing collected packages: h11, httpcore, httpx, replicate\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 replicate-0.21.0\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.28.2-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.13.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.40 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.28.2 validators-0.22.0 watchdog-3.0.0\n",
            "Collecting web3==5.17\n",
            "  Downloading web3-5.17.0-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.3/469.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting eth-abi<3.0.0,>=2.0.0b6 (from web3==5.17)\n",
            "  Downloading eth_abi-2.2.0-py3-none-any.whl (28 kB)\n",
            "Collecting eth-account<0.6.0,>=0.5.3 (from web3==5.17)\n",
            "  Downloading eth_account-0.5.9-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting eth-hash[pycryptodome]<1.0.0,>=0.2.0 (from web3==5.17)\n",
            "  Downloading eth_hash-0.5.2-py3-none-any.whl (8.6 kB)\n",
            "Collecting eth-typing<3.0.0,>=2.0.0 (from web3==5.17)\n",
            "  Downloading eth_typing-2.3.0-py3-none-any.whl (6.2 kB)\n",
            "Collecting eth-utils<2.0.0,>=1.9.5 (from web3==5.17)\n",
            "  Downloading eth_utils-1.10.0-py3-none-any.whl (24 kB)\n",
            "Collecting hexbytes<1.0.0,>=0.1.0 (from web3==5.17)\n",
            "  Downloading hexbytes-0.3.1-py3-none-any.whl (5.9 kB)\n",
            "Collecting ipfshttpclient==0.7.0a1 (from web3==5.17)\n",
            "  Downloading ipfshttpclient-0.7.0a1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema<4.0.0,>=3.2.0 (from web3==5.17)\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lru-dict<2.0.0,>=1.1.6 (from web3==5.17)\n",
            "  Downloading lru_dict-1.3.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: protobuf<4,>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from web3==5.17) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from web3==5.17) (2.31.0)\n",
            "Collecting websockets<9.0.0,>=8.1.0 (from web3==5.17)\n",
            "  Downloading websockets-8.1.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting multiaddr>=0.0.7 (from ipfshttpclient==0.7.0a1->web3==5.17)\n",
            "  Downloading multiaddr-0.0.9-py2.py3-none-any.whl (16 kB)\n",
            "Collecting parsimonious<0.9.0,>=0.8.0 (from eth-abi<3.0.0,>=2.0.0b6->web3==5.17)\n",
            "  Downloading parsimonious-0.8.1.tar.gz (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitarray<3,>=1.2.1 (from eth-account<0.6.0,>=0.5.3->web3==5.17)\n",
            "  Downloading bitarray-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting eth-keyfile<0.6.0,>=0.5.0 (from eth-account<0.6.0,>=0.5.3->web3==5.17)\n",
            "  Downloading eth_keyfile-0.5.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting eth-keys<0.4.0,>=0.3.4 (from eth-account<0.6.0,>=0.5.3->web3==5.17)\n",
            "  Downloading eth_keys-0.3.4-py3-none-any.whl (21 kB)\n",
            "Collecting eth-rlp<2,>=0.1.2 (from eth-account<0.6.0,>=0.5.3->web3==5.17)\n",
            "  Downloading eth_rlp-0.3.0-py3-none-any.whl (5.0 kB)\n",
            "Collecting rlp<3,>=1.0.0 (from eth-account<0.6.0,>=0.5.3->web3==5.17)\n",
            "  Downloading rlp-2.0.1-py2.py3-none-any.whl (20 kB)\n",
            "Collecting pycryptodome<4,>=3.6.6 (from eth-hash[pycryptodome]<1.0.0,>=0.2.0->web3==5.17)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of eth-utils to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting eth-utils<2.0.0,>=1.9.5 (from web3==5.17)\n",
            "  Downloading eth_utils-1.9.5-py3-none-any.whl (23 kB)\n",
            "Collecting cytoolz<1.0.0,>=0.10.1 (from eth-utils<2.0.0,>=1.9.5->web3==5.17)\n",
            "  Downloading cytoolz-0.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.0.0,>=3.2.0->web3==5.17) (23.1.0)\n",
            "Collecting pyrsistent>=0.14.0 (from jsonschema<4.0.0,>=3.2.0->web3==5.17)\n",
            "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.0.0,>=3.2.0->web3==5.17) (67.7.2)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.0.0,>=3.2.0->web3==5.17) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.16.0->web3==5.17) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.16.0->web3==5.17) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.16.0->web3==5.17) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.16.0->web3==5.17) (2023.7.22)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz<1.0.0,>=0.10.1->eth-utils<2.0.0,>=1.9.5->web3==5.17) (0.12.0)\n",
            "INFO: pip is looking at multiple versions of eth-rlp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting eth-rlp<2,>=0.1.2 (from eth-account<0.6.0,>=0.5.3->web3==5.17)\n",
            "  Downloading eth_rlp-0.2.1-py3-none-any.whl (5.0 kB)\n",
            "Collecting varint (from multiaddr>=0.0.7->ipfshttpclient==0.7.0a1->web3==5.17)\n",
            "  Downloading varint-1.0.2.tar.gz (1.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting base58 (from multiaddr>=0.0.7->ipfshttpclient==0.7.0a1->web3==5.17)\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting netaddr (from multiaddr>=0.0.7->ipfshttpclient==0.7.0a1->web3==5.17)\n",
            "  Downloading netaddr-0.9.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: websockets, parsimonious, varint\n",
            "  Building wheel for websockets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for websockets: filename=websockets-8.1-cp310-cp310-linux_x86_64.whl size=73428 sha256=69d10fee9cf598ee5e949655c30d0b93c3d0b9c0ee31bd0ba174c2cb814c34db\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/3f/c7/9993dad06631d258fb8a01677090029dbdbd884a6199c31483\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-py3-none-any.whl size=42707 sha256=b47f58951bc1e5271a44b803c870a9bae0a53e9ccf8638782ef93e5676ef6143\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/12/f1/7a2f39b30d6780ae9f2be9a52056595e0d97c1b4531d183085\n",
            "  Building wheel for varint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for varint: filename=varint-1.0.2-py3-none-any.whl size=1963 sha256=67f2a2ef9c92b13d79ff05ce07cfe3f0a04f5b2f9011c392f304bb8e2e34b5a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/48/5e/33919c52a2a695a512ca394a5308dd12626a40bbcd288de814\n",
            "Successfully built websockets parsimonious varint\n",
            "Installing collected packages: varint, netaddr, bitarray, websockets, pyrsistent, pycryptodome, parsimonious, lru-dict, hexbytes, eth-typing, eth-hash, cytoolz, base58, multiaddr, jsonschema, eth-utils, rlp, ipfshttpclient, eth-keys, eth-abi, eth-rlp, eth-keyfile, eth-account, web3\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.19.2\n",
            "    Uninstalling jsonschema-4.19.2:\n",
            "      Successfully uninstalled jsonschema-4.19.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed base58-2.1.1 bitarray-2.8.3 cytoolz-0.12.2 eth-abi-2.2.0 eth-account-0.5.9 eth-hash-0.5.2 eth-keyfile-0.5.1 eth-keys-0.3.4 eth-rlp-0.2.1 eth-typing-2.3.0 eth-utils-1.9.5 hexbytes-0.3.1 ipfshttpclient-0.7.0a1 jsonschema-3.2.0 lru-dict-1.3.0 multiaddr-0.0.9 netaddr-0.9.0 parsimonious-0.8.1 pycryptodome-3.19.0 pyrsistent-0.20.0 rlp-2.0.1 varint-1.0.2 web3-5.17.0 websockets-8.1\n",
            "Collecting eth-tester==0.5.0b3\n",
            "  Downloading eth_tester-0.5.0b3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: eth-abi<3.0.0,>=2.0.0b4 in /usr/local/lib/python3.10/dist-packages (from eth-tester==0.5.0b3) (2.2.0)\n",
            "Requirement already satisfied: eth-keys<0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from eth-tester==0.5.0b3) (0.3.4)\n",
            "Requirement already satisfied: eth-utils<2.0.0,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from eth-tester==0.5.0b3) (1.9.5)\n",
            "Requirement already satisfied: rlp<3,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from eth-tester==0.5.0b3) (2.0.1)\n",
            "Collecting semantic-version<3.0.0,>=2.6.0 (from eth-tester==0.5.0b3)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: eth-typing<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from eth-abi<3.0.0,>=2.0.0b4->eth-tester==0.5.0b3) (2.3.0)\n",
            "Requirement already satisfied: parsimonious<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from eth-abi<3.0.0,>=2.0.0b4->eth-tester==0.5.0b3) (0.8.1)\n",
            "Requirement already satisfied: eth-hash<1.0.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from eth-utils<2.0.0,>=1.4.1->eth-tester==0.5.0b3) (0.5.2)\n",
            "Requirement already satisfied: cytoolz<1.0.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from eth-utils<2.0.0,>=1.4.1->eth-tester==0.5.0b3) (0.12.2)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz<1.0.0,>=0.10.1->eth-utils<2.0.0,>=1.4.1->eth-tester==0.5.0b3) (0.12.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from parsimonious<0.9.0,>=0.8.0->eth-abi<3.0.0,>=2.0.0b4->eth-tester==0.5.0b3) (1.16.0)\n",
            "Installing collected packages: semantic-version, eth-tester\n",
            "Successfully installed eth-tester-0.5.0b3 semantic-version-2.10.0\n",
            "Collecting mnemonic\n",
            "  Downloading mnemonic-0.20-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mnemonic\n",
            "Successfully installed mnemonic-0.20\n",
            "Collecting bip44\n",
            "  Downloading bip44-0.1.4-py3-none-any.whl (5.1 kB)\n",
            "Collecting bip32<4.0,>=3.1 (from bip44)\n",
            "  Downloading bip32-3.4-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: mnemonic<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from bip44) (0.20)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.16.0 in /usr/local/lib/python3.10/dist-packages (from bip44) (3.19.0)\n",
            "Requirement already satisfied: base58~=2.0 in /usr/local/lib/python3.10/dist-packages (from bip32<4.0,>=3.1->bip44) (2.1.1)\n",
            "Collecting coincurve<19,>=15.0 (from bip32<4.0,>=3.1->bip44)\n",
            "  Downloading coincurve-18.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asn1crypto (from coincurve<19,>=15.0->bip32<4.0,>=3.1->bip44)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from coincurve<19,>=15.0->bip32<4.0,>=3.1->bip44) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.3.0->coincurve<19,>=15.0->bip32<4.0,>=3.1->bip44) (2.21)\n",
            "Installing collected packages: asn1crypto, coincurve, bip32, bip44\n",
            "Successfully installed asn1crypto-1.5.1 bip32-3.4 bip44-0.1.4 coincurve-18.0.0\n"
          ]
        }
      ],
      "source": [
        "# # Install replicate Python client and other required packages for Google Colab IDE\n",
        "# !pip install python-dotenv\n",
        "# !pip install replicate\n",
        "# !pip install streamlit\n",
        "# !pip install web3==5.17 #Creating dependency issue with jsonschema?\n",
        "# !pip install web3\n",
        "# !pip install eth-tester==0.5.0b3\n",
        "# !pip install mnemonic\n",
        "# !pip install bip44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "skaUT-P5tgjh",
        "outputId": "74223d86-377b-46d9-b443-f7888893ae3c"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os # Methods for interacting with the operating system, including management of environment variables\n",
        "from dotenv import load_dotenv # Method for loading local environment file\n",
        "import replicate # Replicate library for AI-generated Avatar and other machine learning applications\n",
        "import streamlit as st # Streamlit front-end web browser UI\n",
        "from web3 import Web3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V9jmFCSk44fk"
      },
      "outputs": [],
      "source": [
        "#!jsonschema --version # Google Colab appears to be requiring jsonschema 3.2.0, while our local dev environment uses 4.19.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RURy7KDy0-qf"
      },
      "outputs": [],
      "source": [
        "w3 = Web3(Web3.HTTPProvider(\"HTTP://127.0.0.1:8545\")) # Create local blockchain Ganache connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "ab1mXDuRu4cj",
        "outputId": "363efb06-e1f9-44a7-e3f5-fba73a1e1e8f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f07edb78-316e-4d12-a567-a9b3efd3df73\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f07edb78-316e-4d12-a567-a9b3efd3df73\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving .env to .env (1)\n"
          ]
        }
      ],
      "source": [
        "# Load .env file, containing Replicate API Token, locally to Google Colab Jupyter Notebook\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6JxbDj62joR",
        "outputId": "64a1e51a-14ab-4fe1-cbc3-8efc947daade"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load local environment .env file for secure api reference\n",
        "load_dotenv() # Returns True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F3ZvPDmIwbhR"
      },
      "outputs": [],
      "source": [
        "# About the Replicate library that we are using for our Dao's AI-generated avatars, with potential for other machine learning applications\n",
        "\n",
        "  # Replicate documentation: https://replicate.com/docs\n",
        "\n",
        "  # About Replicate:  1. https://replicate.com/about\n",
        "  #                   2. https://replicate.com/blog/machine-learning-needs-better-tools:\n",
        "\n",
        "    # \"Replicate runs machine learning models in the cloud. We have a library of open-source models that you can run with a few lines of code.\n",
        "    # If you're building your own machine learning models, Replicate makes it easy to deploy them at scale.\"\"\n",
        "\n",
        "    # \"There are roughly two orders of magnitude more software engineers than there are machine learning engineers (~30 million vs. ~500,000).\n",
        "    # By building good tools, we think it is possible for software engineers to use machine learning in the same way they can use normal software.\"\n",
        "\n",
        "    # \"If you try to actually build something with these machine learning models, you find that none of it really works. You spend all day battling\n",
        "    # with messy Python scripts, broken Colab notebooks, perplexing CUDA errors, misshapen tensors. It’s a mess.\"\n",
        "\n",
        "    # \"Normal software used to be like this. If you wanted to build a website 20 years ago it felt like trying to use machine learning today.\n",
        "    # You had to build web servers, authentication systems, user interface components. You were concatenating HTML and SQL by hand, hoping you didn’t\n",
        "    # get owned. To deploy, you uploaded files to an FTP server and waited and hoped for the best.\"\n",
        "\n",
        "    # \"The reason machine learning is so hard to use is not because it’s inherently hard. We just don’t have good tools and abstractions yet. You\n",
        "    # shouldn’t have to understand GPUs to use machine learning, in the same way you don’t have to understand TCP/IP to build a website.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "X9fm7DBtwIN_"
      },
      "outputs": [],
      "source": [
        "# Import Replicate library for AI-generated Avatar and other machine learning applications\n",
        "import replicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NYWv9r51ANlS"
      },
      "outputs": [],
      "source": [
        "# # Save replicate api token to Colab environ\n",
        "# # REPLICATE_API_KEY = os.getenv('REPLICATE_API_TOKEN') # Unable to resolve local .env file reference\n",
        "# REPLICATE_API_KEY = 'r8_MWmqhtJpG7hERByS1WDYAh2Ap4wimPb1o7svr'\n",
        "# #print(REPLICATE_API_KEY)\n",
        "# os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "r8_MWmqhtJpG7hERByS1WDYAh2Ap4wimPb1o7svr\n"
          ]
        }
      ],
      "source": [
        "# Replicate api token reference in VS Code environ\n",
        "REPLICATE_API_TOKEN = os.getenv('REPLICATE_API_KEY')\n",
        "print(REPLICATE_API_TOKEN)\n",
        "os.environ['REPLICATE_API_TOKEN'] = REPLICATE_API_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "!export REPLICATE_API_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce14O90eEr8_"
      },
      "source": [
        "# Create and run a model\n",
        "You can run any public model on Replicate from Python code. The following runs [stability-ai/stable-diffusion](https://replicate.com/stability-ai/stable-diffusion), a latent text-to-image diffusion model capable of generating photo-realistic images given any text input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "avatar_text_input_prompt = 'an astronaut on mars holding flowers, impressionism'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6IPHl1HUVrz9",
        "outputId": "44276ef4-0e6f-4488-e97b-9e51005bd9a8"
      },
      "outputs": [
        {
          "ename": "ReplicateError",
          "evalue": "You did not pass an authentication token",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReplicateError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/bozmbp18/Tresorit/Boz & Company LLC/IAR/Todd Meier/Education/Columbia Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_23_24/local/dao_avatar_ai.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bozmbp18/Tresorit/Boz%20%26%20Company%20LLC/IAR/Todd%20Meier/Education/Columbia%20Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_23_24/local/dao_avatar_ai.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m avatar_model_predicted \u001b[39m=\u001b[39m replicate\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bozmbp18/Tresorit/Boz%20%26%20Company%20LLC/IAR/Todd%20Meier/Education/Columbia%20Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_23_24/local/dao_avatar_ai.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   \u001b[39m'\u001b[39;49m\u001b[39mstability-ai/stable-diffusion:ac732df83cea7fff18b8472768c88ad041fa750ff7682a21affe81863cbe77e4\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bozmbp18/Tresorit/Boz%20%26%20Company%20LLC/IAR/Todd%20Meier/Education/Columbia%20Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_23_24/local/dao_avatar_ai.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mtesting\u001b[39;49m\u001b[39m'\u001b[39;49m}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bozmbp18/Tresorit/Boz%20%26%20Company%20LLC/IAR/Todd%20Meier/Education/Columbia%20Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_23_24/local/dao_avatar_ai.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bozmbp18/Tresorit/Boz%20%26%20Company%20LLC/IAR/Todd%20Meier/Education/Columbia%20Engineering/CU-VIRT-FIN-PT-06-2023-U-LOLC/GitHub_Repository/CU-VIRT-FIN-PT-06-2023-U-LOLC/Week_23_24/local/dao_avatar_ai.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m display(avatar_model_predicted)\n",
            "File \u001b[0;32m~/miniconda3/envs/dev2/lib/python3.10/site-packages/replicate/client.py:141\u001b[0m, in \u001b[0;36mClient.run\u001b[0;34m(self, ref, input, **params)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    133\u001b[0m     ref: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    134\u001b[0m     \u001b[39minput\u001b[39m: Optional[Dict[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams: Unpack[\u001b[39m\"\u001b[39m\u001b[39mPredictions.CreatePredictionParams\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    136\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Any, Iterator[Any]]:  \u001b[39m# noqa: ANN401\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m    Run a model and wait for its output.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m run(\u001b[39mself\u001b[39;49m, ref, \u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
            "File \u001b[0;32m~/miniconda3/envs/dev2/lib/python3.10/site-packages/replicate/run.py:37\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(client, ref, input, **params)\u001b[0m\n\u001b[1;32m     34\u001b[0m name \u001b[39m=\u001b[39m match\u001b[39m.\u001b[39mgroup(\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m version_id \u001b[39m=\u001b[39m match\u001b[39m.\u001b[39mgroup(\u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m prediction \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mpredictions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     38\u001b[0m     version\u001b[39m=\u001b[39;49mversion_id, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m \u001b[39mor\u001b[39;49;00m {}, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m owner \u001b[39mand\u001b[39;00m name:\n\u001b[1;32m     42\u001b[0m     version \u001b[39m=\u001b[39m Versions(client, model\u001b[39m=\u001b[39m(owner, name))\u001b[39m.\u001b[39mget(version_id)\n",
            "File \u001b[0;32m~/miniconda3/envs/dev2/lib/python3.10/site-packages/replicate/prediction.py:288\u001b[0m, in \u001b[0;36mPredictions.create\u001b[0;34m(self, version, input, **params)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39mCreate a new prediction for the specified model version.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m body \u001b[39m=\u001b[39m _create_prediction_body(\n\u001b[1;32m    284\u001b[0m     version,\n\u001b[1;32m    285\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m    286\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m )\n\u001b[0;32m--> 288\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    290\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/v1/predictions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    291\u001b[0m     json\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    292\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[39mreturn\u001b[39;00m _json_to_prediction(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client, resp\u001b[39m.\u001b[39mjson())\n",
            "File \u001b[0;32m~/miniconda3/envs/dev2/lib/python3.10/site-packages/replicate/client.py:79\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, method, path, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_request\u001b[39m(\u001b[39mself\u001b[39m, method: \u001b[39mstr\u001b[39m, path: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m httpx\u001b[39m.\u001b[39mResponse:\n\u001b[1;32m     78\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mrequest(method, path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 79\u001b[0m     _raise_for_status(resp)\n\u001b[1;32m     81\u001b[0m     \u001b[39mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/miniconda3/envs/dev2/lib/python3.10/site-packages/replicate/client.py:328\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[0;34m(resp)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_for_status\u001b[39m(resp: httpx\u001b[39m.\u001b[39mResponse) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m400\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m \u001b[39m600\u001b[39m:\n\u001b[0;32m--> 328\u001b[0m         \u001b[39mraise\u001b[39;00m ReplicateError(resp\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mdetail\u001b[39m\u001b[39m\"\u001b[39m])\n",
            "\u001b[0;31mReplicateError\u001b[0m: You did not pass an authentication token"
          ]
        }
      ],
      "source": [
        "avatar_model_predicted = replicate.run(\n",
        "  'stability-ai/stable-diffusion:ac732df83cea7fff18b8472768c88ad041fa750ff7682a21affe81863cbe77e4',\n",
        "  input={'prompt': 'testing'}\n",
        ")\n",
        "\n",
        "display(avatar_model_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QWtq0v1LQOzH"
      },
      "outputs": [],
      "source": [
        "# This avatar object and prediction model may not be supported by free Replicate API version.  Therefore, relying on replicate.run() method above.\n",
        "#avatar_model = replicate.models.get('stability-ai/stable-diffusion')\n",
        "#avatar_model_version = avatar_model.versions.get('f178fa7a1ae43a9a9af01b833b9d2ecf97b1bcb0acfd2dc5dd04895e042863f1')\n",
        "#avatar_model_predict = avatar_model_version.predict(prompt='an astronaut, impressionism')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "xvKiQV-uEr9A",
        "outputId": "ec3b188c-26df-486d-ab49-6f57df591baf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://replicate.delivery/pbxt/EyfbuWfi2ZrrSEZKRtpoKCDSAOsYdp4otdqHHIQAKLctfmrhA/out-0.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "Image(url=output[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCQKtiOqEr9F"
      },
      "source": [
        "# Additional Replicate information and resources:\n",
        "\n",
        "- Explore collection of hosted [models](https://replicate.com/explore)\n",
        "\n",
        "\n",
        "\n",
        "- Learn how to integrate with [LangChain](https://python.langchain.com/en/latest/modules/models/llms/integrations/replicate.html)\n",
        "\n",
        "\n",
        "\n",
        "- Note that you can also run models with the raw HTTP API. Refer to the [HTTP API reference](https://replicate.com/docs/reference/http) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNqXro-iEvn5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EErfFyHUExdP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
